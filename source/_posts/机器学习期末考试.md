<img width="395" height="100" alt="image" src="https://github.com/user-attachments/assets/54eb9fa0-827b-4d43-9a47-eb409f1b6418" /><img width="128" height="39" alt="image" src="https://github.com/user-attachments/assets/ed7bcbb1-7b8b-4e5c-b9a4-0e51065052db" />---
title: 机器学期期末考试内容
description: 机器学期期末考试内容
tags:
  - Hexo
  - GitHub Actions
categories:
  - 机器学习
date: 2025-12-05 15:00:00
---
# 1.多重分类

```python
# ============================================
# 1. 问题定义
# ============================================
# 目标：预测 Credit_Score（Good / Standard / Poor）
# 评价指标：f1-macro
#
# 1. 问题定义
# 2. 加载库和数据
# 3. 探索性数据分析（EDA）
# 4. 数据预处理
# 5. 拆分验证数据
# 6. 机器学习训练与评估

# ============================================
# 2. 加载库和数据
# ============================================
import pandas as pd

# 用老师 PPT 的在线数据路径（PPT 原样）
train = pd.read_csv("https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/score_train.csv")
test = pd.read_csv("https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/score_test.csv")

# ============================================
# 3. 探索性数据分析（EDA）
# ============================================
# (1) 查看数据大小
print("===== 数据大小 =====")
print("Train Shape:", train.shape)
print("Test Shape :", test.shape)
print("\n")

# (2) 查看数据类型
print("===== 数据类型 =====")
print(train.info())
print("\n")

# (3) 查看缺失值数量
print("===== train 缺失值数量 =====")
print(train.isnull().sum().sum())

print("\n===== test 缺失值数量 =====")
print(test.isnull().sum().sum())
print("\n")

# (4) 查看目标值的分布
print("===== Credit_Score 频率 =====")
print(train["Credit_Score"].value_counts())

# ============================================
# 4. 数据预处理
# ============================================
# 从训练数据中分离目标变量
target = train.pop("Credit_Score")

# 对类别变量做独热编码（One-hot）
train = pd.get_dummies(train)
test = pd.get_dummies(test)

# ============================================
# 5. 拆分验证数据
# ============================================
from sklearn.model_selection import train_test_split

X_tr, X_val, y_tr, y_val = train_test_split(
    train, target, test_size=0.2, random_state=0
)

print("\n===== 拆分后的数据大小 =====")
print(X_tr.shape, X_val.shape, y_tr.shape, y_val.shape)

# ============================================
# 6. 机器学习训练与评估
# ============================================
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=0)
rf.fit(X_tr, y_tr)

pred = rf.predict(X_val)

from sklearn.metrics import f1_score
print("\n f1-macro:", f1_score(y_val, pred, average="macro"))

# 7. 预测及结果文件生成
pred = rf.predict(test)
submit = pd.DataFrame({'pred':pred})
submit.to_csv("result.csv", index=False)

# 提交文件确认
print(“\n ===== 提交文件（5个示例）====”)
print(pd.read_csv("result.csv").head())
```

# 2.回归预测

```python
# ============================================
# 1. 问题定义
# ============================================
# 目标：预测笔记本电脑价格 Price
# 评价指标：R²（决定系数）

# 1. 问题定义
# 2. 加载库和数据
# 3. 探索性数据分析（EDA）
# 4. 数据预处理
# 5. 拆分验证数据
# 6. 机器学习训练与评估

# ============================================
# 2. 加载库和数据
# ============================================
import pandas as pd

train = pd.read_csv("https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/laptop_train.csv")
test = pd.read_csv("https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/laptop_test.csv")

# ============================================
# 3. 探索性数据分析（EDA）
# ============================================
# (1) 数据大小
print("===== 数据大小 =====")
print("Train Shape:", train.shape)
print("Test Shape :", test.shape)

# (2) 数据类型
print("\n===== 数据类型 =====")
print(train.info())

# (3) 缺失值
print("\n===== train 缺失值 =====")
print(train.isnull().sum().sum())

print("\n===== test 缺失值 =====")
print(test.isnull().sum().sum())

# (4) 目标值基本统计
print("\n===== Price 统计 =====")
print(train["Price"].describe())

# ============================================
# 4. 数据预处理
# ============================================
# 分离目标变量
target = train.pop("Price")

# (1) 填充分类变量缺失值
c_cols = ["Model", "Series", "Processor", "Processor_Gen",
          "Hard_Disk_Capacity", "OS"]

train[c_cols] = train[c_cols].fillna("X")
test[c_cols] = test[c_cols].fillna("X")

# (2) 填充数值变量缺失值
train["RAM"] = train["RAM"].fillna(-1)
test["RAM"] = test["RAM"].fillna(-1)

# (3) 合并后 One-hot 编码
combined = pd.concat([train, test])
combined = pd.get_dummies(combined)

train = combined[:len(train)]
test = combined[len(train):]

# ============================================
# 5. 拆分验证数据
# ============================================
from sklearn.model_selection import train_test_split

X_tr, X_val, y_tr, y_val = train_test_split(
    train, target, test_size=0.2, random_state=0
)

print("\n===== 拆分后的数据大小 =====")
print(X_tr.shape, X_val.shape, y_tr.shape, y_val.shape)

# ============================================
# 6. 机器学习训练与评估
# ============================================
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(random_state=0)
rf.fit(X_tr, y_tr)

pred = rf.predict(X_val)

from sklearn.metrics import r2_score
print("\n R2:", r2_score(y_val, pred))

# 7. 预测及结果文件生成
pred = rf.predict(test)
submit = pd.DataFrame({'pred':pred})
submit.to_csv("result.csv", index=False)

# 提交文件验证
print(“\n ===== 提交文件（5个样本）====”)
print(pd.read_csv("result.csv").head())
```

# 3.二分类

```python
# ============================================
# 1. 问题定义
# ============================================
# 任务：预测患者是否患有糖尿病
# 目标列：Outcome（0 = 正常，1 = 糖尿病）
# 使用 train 数据训练模型，再对 test 数据预测
# 提交文件格式：
#   1) pred：预测为糖尿病的概率
#   2) 文件名：result.csv
# 性能评价：ROC-AUC

# 1. 问题定义
# 2. 加载库和数据
# 3. 探索性数据分析（EDA）
# 4. 数据预处理
# 5. 拆分验证数据
# 6. 机器学习训练与评估
# 7. 生成预测文件（result.csv）

# ============================================
# 2. 加载库和数据
# ============================================
import pandas as pd

# PPT 中的加载方式（老师提供的 URL）
train = pd.read_csv("https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/diabetes_train.csv")
test = pd.read_csv("https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/diabetes_test.csv")

# ============================================
# 3. 探索性数据分析（EDA）
# ============================================

# (1) 数据大小
print("===== 数据大小 =====")
print("Train Shape:", train.shape)
print("Test Shape :", test.shape)
print("\n")

# (2) 数据类型
print("===== 数据类型 =====")
print(train.info())
print("\n")

# (3) 缺失值数量
print("===== train 缺失值数量 =====")
print(train.isnull().sum().sum())     # 所有缺失值总和
print("\n")

print("===== test 缺失值数量 =====")
print(test.isnull().sum().sum())
print("\n")

# (4) 目标值分布（分类 group 数量）
print("===== Outcome 频数 =====")
print(train["Outcome"].value_counts())

# ============================================
# 4. 数据预处理
# ============================================
# 本题无缺失值 → 直接提取目标
target = train.pop("Outcome")

# 说明：
# 分类问题若 target 是类别型，需要做 One-hot
# 但本题所有特征都是数值型，因此不需要 dummy coding

# ============================================
# 5. 拆分验证数据
# ============================================
from sklearn.model_selection import train_test_split

X_tr, X_val, y_tr, y_val = train_test_split(
    train, target, test_size=0.2, random_state=0
)

print("\n===== 拆分后数据大小 =====")
print(X_tr.shape, X_val.shape, y_tr.shape, y_val.shape)

# ============================================
# 6. 机器学习模型训练与评估
# ============================================
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=0)
rf.fit(X_tr, y_tr)

# 使用 predict_proba 获得概率
pred_val = rf.predict_proba(X_val)

# pred_val[:, 1] → 属于“1（糖尿病）”的概率

# ============================================
# 7. 生成最终预测文件（result.csv）
# ============================================
pred_test = rf.predict_proba(test)

# 取类别 1 的概率作为最终预测值
submit = pd.DataFrame({"pred": pred_test[:, 1]})

submit.to_csv("result.csv", index=False)

print("\n===== 提交文件（前 5 行） =====")
print(pd.read_csv("result.csv").head())
```

# 4.11题小题

```python
#【问题 1】在给定的数据集中，从头开始，仅使用 80% 的数据，用中位数填充“f1”列中的缺失值。求填充前后的样本标准差，并计算两个样本标准差之差。（两个样本标准差之差以绝对值计算，并四舍五入到小数点后两位。）
import pandas as pd
# 读取数据
df = pd.read_csv("members.csv")
# 前 80% 数据
n = int(len(df) * 0.8)
df2 = df.iloc[:n]
# 计算 f1 填充前的标准差
std_before = df2['f1'].std()
# 缺失值填充为平均值
df2['f1'] = df2['f1'].fillna(df2['f1'].mean())
# 填充后的标准差
std_after = df2['f1'].std()
# 差值（绝对值，四舍五入 2 位）
result = round(abs(std_before - std_after), 2)
print(result)

#【问题 2】在给定数据集的“年龄”列中添加所有异常值。异常值定义为与平均值偏差超过“1.5 个标准差”的值。
import pandas as pd
df = pd.read_csv("members.csv")
m = df['age'].mean()
s = df['age'].std()
# 定义异常范围
min_v = m - 1.5 * s
max_v = m + 1.5 * s
# 找出异常值
outliers = df[(df['age'] < min_v) | (df['age'] > max_v)]
# 求 age 的总和
print(outliers['age'].sum())

#【问题 3】删除包含缺失值的数据行（记录），并仅使用前 70% 的数据计算“f1”列的第一四分位数。（去除小数点，输出整数。）
import pandas as pd
df = pd.read_csv("members.csv")
# 删除缺失值
df = df.dropna()
# 取前 70%
n = int(len(df) * 0.7)
df2 = df.iloc[:n]
# f1 的第一四分位数
q1 = df2['f1'].quantile(0.25)
print(int(q1))

# 第 4 题：members.csv — 找出缺失值最多的列名
import pandas as pd
df = pd.read_csv("members.csv")
# 按列统计缺失
missing = df.isnull().sum()
# 找最大缺失列
print(missing.idxmax())

# [问题 5】计算“年龄”列的第 3 个四分位数和第 1 个四分位数之差的绝对值，去掉小数部分，并以整数形式输出。
import pandas as pd
df = pd.read_csv("data4-1.csv")
q1 = df['age'].quantile(0.25)
q3 = df['age'].quantile(0.75)
result = abs(q3 - q1)
print(int(result))

# [问题 6】找出所有反应中“喜欢”和“哇”的综合反应比例大于 40% 且小于 50% 的数据，并找出 type 列为“视频”的数据数量。
import pandas as pd
df = pd.read_csv("data4-2.csv")
# 新增列：（loves + wows）/ reactions
df["rate"] = (df["loves"] + df["wows"]) / df["reactions"]
# 条件：rate 在 0.4～0.5 且 type=video
cond = df[(df["rate"] >= 0.4) & (df["rate"] <= 0.5) & (df["type"] == "video")]
print(len(cond))

# [问题7】计算正常BMI人群数量与高危人群数量之差的绝对值。（结果以整数形式输出）
import pandas as pd
df = pd.read_csv("data5-2.csv")
# 计算 BMI
df["BMI"] = df["weight"] / (df["height"] / 100) ** 2
# 正常体重（18.5~23）
normal = df[(df["BMI"] >= 18.5) & (df["BMI"] <= 23)]
# 危险体重（23~25）
danger = df[(df["BMI"] > 23) & (df["BMI"] <= 25)]
# 两者差值
print(abs(len(normal) - len(danger)))

#【问题 8】删除包含缺失值的行后，找出每位学生选修次数最多的科目。然后，将该科目的分数标准化（采用标准量表），并找出最大的标准化值。（结果保留三位小数。）
import pandas as pd
df = pd.read_csv("student_assessment.csv")
# 删除缺失
df = df.dropna()
# 找修课最多的科目
top_course = df['id_assessment'].value_counts().idxmax()
# 只看该科目
sub = df[df['id_assessment'] == top_course]
# 准化
scaler = StandardScaler()
sub['score_z'] = scaler.fit_transform(sub[['score']])
# 最大值（3 位小数）
print(round(sub['score_z'].max(), 3))

#【问题 9】使用四分位距 (IQR) 查找二氧化碳 (CO2) 异常值的数量。
import pandas as pd
df = pd.read_csv("air_quality.csv")
q1 = df['CO2'].quantile(0.25)
q3 = df['CO2'].quantile(0.75)
iqr = q3 - q1
min_v = q1 - 1.5 * iqr
max_v = q3 + 1.5 * iqr
outliers = df[(df["CO2"] < min_v) | (df["CO2"] > max_v)]
print(len(outliers))

#【问题 10】
# 1) 计算各大洲的平均啤酒消费量（“beer_servings”），并找出平均消费量最高的大洲。
# 2) 在步骤 1 中确定的大洲中，找出啤酒消费量排名第五的国家（“country”）。

# 1) 各大洲平均啤酒消费量
continent_mean = df.groupby(‘continent’)[‘beer_servings’].mean()
# 平均消费量最高的洲
top_continent = continent_mean.idxmax()

# 2) 按啤酒消费量排序该大陆国家
cond = df[‘continent’] == top_continent
df = df[cond]
df = df.sort_values(‘beer_servings’, ascending=False)

# 啤酒消费量第5名
df.iloc[4, 1]

#【问题 11】
# 1) 对给定数据中的“co”和“nmhc”列进行最小-最大缩放。
# 2) 分别计算缩放后的“co”和“nmhc”列的标准差。
# 3) 从“co”列的标准差中减去“nmhc”列的标准差，并将结果四舍五入到小数点后三位。
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

df = pd.read_csv(“chem.csv”)

# 1) 极值缩放
scaler = MinMaxScaler()
df[‘co_scaled’] = scaler.fit_transform(df[[‘co’]])
df[‘nmhc_scaled’] = scaler.fit_transform(df[[‘nmhc’]])

# 2) 计算标准差
co_std = df[‘co_scaled’].std()
nmhc_std = df[‘nmhc_scaled’].std()

# 3) 计算标准差差值并四舍五入
std_diff = round(co_std - nmhc_std, 3)
print(std_diff)
```
